{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "mnist_ann.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy_eNWXjxHxG"
      },
      "source": [
        "# MNINST 분류기 - ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TN9Tj7QxHxI"
      },
      "source": [
        "### 라이브러리 임포트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1KIo7RPxHxI"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enZ5oTJC215S",
        "outputId": "fe6afab6-3f5a-42b1-f72d-f00919b91d7b"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIZOoeJdxHxJ"
      },
      "source": [
        "#### MNIST 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "qGj5Yh_zxHxK"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-nRc0oTzlfe"
      },
      "source": [
        "### MNIST 데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1pNBXpAhonE"
      },
      "source": [
        "X_valid = X_train[55000:]\n",
        "y_valid = y_train[55000:]\n",
        "\n",
        "X_train = X_train[:55000]\n",
        "y_train = y_train[:55000]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10PquKSxxHxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ddb4dc0-16b2-4c1b-e040-3d30fbfe3918"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkPd8d1TxHxL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75f5c553-0821-4a2c-80bb-34e5a4ed0cf9"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000,)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4KycfPOxHxN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "745e9475-080c-43b1-960f-2c1c78916a28"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29qKimW6xHxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68d05c01-e562-49bf-cc84-9666176d6694"
      },
      "source": [
        "y_train[0:10]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "givkTlyZxHxN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "56d45516-7e41-4c76-cbcc-89436c9ab0a5"
      },
      "source": [
        "plt.imshow(X_train[0], cmap='Greys')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0932b40e90>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc485XkvxHxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d0da48-cc19-4f8c-89d9-fae4d53f8a69"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI2Pomf2xHxO"
      },
      "source": [
        "### 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2d1svE-0CTA"
      },
      "source": [
        "신경망의 입력층과 출력층의 크기에 맞도록 데이터의 크기를 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hzBxUJ4iVCl",
        "outputId": "137d7aa7-39ab-428c-c10e-60c7656d9d24"
      },
      "source": [
        "X_valid"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P34mv84hxHxO"
      },
      "source": [
        "X_train = X_train.reshape(55000, 784).astype('float32')\n",
        "X_valid = X_valid.reshape(5000, 784).astype('float32')\n",
        "X_test = X_test.reshape(10000, 784).astype('float32')"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dye9Rrv0TMI"
      },
      "source": [
        "데이터 정규화 : 입력값을 0과 1사이의 범위로 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1aIBfgY4yUH",
        "outputId": "a11e8362-2494-4b7b-beac-9e1d7151bff8"
      },
      "source": [
        "1/255.0"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00392156862745098"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWMc4UZmxHxP"
      },
      "source": [
        "X_train /= 255\n",
        "X_valid /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlhxNm-nxHxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f25c936-9f05-49ba-8297-1382e6ad7757"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
              "       0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
              "       0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n",
              "       0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n",
              "       0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n",
              "       0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n",
              "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n",
              "       0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
              "       0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.54509807,\n",
              "       0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n",
              "       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n",
              "       0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n",
              "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
              "       0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n",
              "       0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n",
              "       0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n",
              "       0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
              "       0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n",
              "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n",
              "       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n",
              "       0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFrYpRkP0gTn"
      },
      "source": [
        "레이블을 원핫 인코딩으로 바꾸기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUlPjR8IxHxP"
      },
      "source": [
        "n_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
        "y_valid = keras.utils.to_categorical(y_valid, n_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, n_classes)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sKy7YomxHxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e021fe19-3942-4f66-a7d0-2fb2c96d2041"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uCfvSbTxHxQ"
      },
      "source": [
        "### 신경망 구조 설계"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zO9xNfkxHxQ"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, activation='sigmoid', input_shape=(784,)))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f5bfv04xHxQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdd2ccea-0248-4372-afa4-af17d56541b5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpyhpGsCxHxQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cdf4041-b40b-469e-c448-01f8e953391b"
      },
      "source": [
        "(784*64) + 64"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50240"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyDRiY3OxHxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06de25ca-4b4f-49bd-d1a0-91987ad1f7eb"
      },
      "source": [
        "(64*10) + 10"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "650"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ypf9tqbitom",
        "outputId": "8cb952b2-e97d-48c7-97fd-ffcc74482aff"
      },
      "source": [
        "# Trainable params: 50,890\n",
        "50240 + 650 "
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50890"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCr6fKAUxHxR"
      },
      "source": [
        "### 신경망 모델 컴파일"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wh-sD2SxHxR"
      },
      "source": [
        "model.compile(loss='mean_squared_error', \n",
        "              optimizer=SGD(learning_rate=0.01), \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4Ebh8sTxHxR"
      },
      "source": [
        "### 신경망 모델 훈련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQXDUkYBxHxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4d62688-a42b-4ccf-8fa9-941754ecc99b"
      },
      "source": [
        "model.fit(X_train, y_train, \n",
        "          batch_size=128, \n",
        "          epochs=200, \n",
        "          verbose=1, \n",
        "          validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "430/430 [==============================] - 2s 3ms/step - loss: 0.0922 - accuracy: 0.1122 - val_loss: 0.0915 - val_accuracy: 0.1166\n",
            "Epoch 2/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0912 - accuracy: 0.1293 - val_loss: 0.0908 - val_accuracy: 0.1334\n",
            "Epoch 3/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.1514 - val_loss: 0.0903 - val_accuracy: 0.1552\n",
            "Epoch 4/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0902 - accuracy: 0.1717 - val_loss: 0.0899 - val_accuracy: 0.1814\n",
            "Epoch 5/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0898 - accuracy: 0.1947 - val_loss: 0.0895 - val_accuracy: 0.2082\n",
            "Epoch 6/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0894 - accuracy: 0.2192 - val_loss: 0.0891 - val_accuracy: 0.2358\n",
            "Epoch 7/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0891 - accuracy: 0.2433 - val_loss: 0.0888 - val_accuracy: 0.2602\n",
            "Epoch 8/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0888 - accuracy: 0.2650 - val_loss: 0.0884 - val_accuracy: 0.2778\n",
            "Epoch 9/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0885 - accuracy: 0.2851 - val_loss: 0.0881 - val_accuracy: 0.2988\n",
            "Epoch 10/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0882 - accuracy: 0.3046 - val_loss: 0.0878 - val_accuracy: 0.3220\n",
            "Epoch 11/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0878 - accuracy: 0.3224 - val_loss: 0.0875 - val_accuracy: 0.3418\n",
            "Epoch 12/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0875 - accuracy: 0.3394 - val_loss: 0.0872 - val_accuracy: 0.3590\n",
            "Epoch 13/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0872 - accuracy: 0.3555 - val_loss: 0.0869 - val_accuracy: 0.3768\n",
            "Epoch 14/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0869 - accuracy: 0.3696 - val_loss: 0.0865 - val_accuracy: 0.3932\n",
            "Epoch 15/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0866 - accuracy: 0.3833 - val_loss: 0.0862 - val_accuracy: 0.4058\n",
            "Epoch 16/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0863 - accuracy: 0.3948 - val_loss: 0.0859 - val_accuracy: 0.4188\n",
            "Epoch 17/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0860 - accuracy: 0.4054 - val_loss: 0.0856 - val_accuracy: 0.4292\n",
            "Epoch 18/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0857 - accuracy: 0.4145 - val_loss: 0.0853 - val_accuracy: 0.4388\n",
            "Epoch 19/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0854 - accuracy: 0.4224 - val_loss: 0.0849 - val_accuracy: 0.4478\n",
            "Epoch 20/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0851 - accuracy: 0.4311 - val_loss: 0.0846 - val_accuracy: 0.4570\n",
            "Epoch 21/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0848 - accuracy: 0.4452 - val_loss: 0.0843 - val_accuracy: 0.4708\n",
            "Epoch 22/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0844 - accuracy: 0.4625 - val_loss: 0.0839 - val_accuracy: 0.4878\n",
            "Epoch 23/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0841 - accuracy: 0.4833 - val_loss: 0.0836 - val_accuracy: 0.5104\n",
            "Epoch 24/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0838 - accuracy: 0.5063 - val_loss: 0.0832 - val_accuracy: 0.5314\n",
            "Epoch 25/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0834 - accuracy: 0.5249 - val_loss: 0.0829 - val_accuracy: 0.5492\n",
            "Epoch 26/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0831 - accuracy: 0.5386 - val_loss: 0.0825 - val_accuracy: 0.5604\n",
            "Epoch 27/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0827 - accuracy: 0.5477 - val_loss: 0.0821 - val_accuracy: 0.5678\n",
            "Epoch 28/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0823 - accuracy: 0.5556 - val_loss: 0.0817 - val_accuracy: 0.5740\n",
            "Epoch 29/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0820 - accuracy: 0.5583 - val_loss: 0.0814 - val_accuracy: 0.5772\n",
            "Epoch 30/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0816 - accuracy: 0.5621 - val_loss: 0.0810 - val_accuracy: 0.5806\n",
            "Epoch 31/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0812 - accuracy: 0.5642 - val_loss: 0.0805 - val_accuracy: 0.5816\n",
            "Epoch 32/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0808 - accuracy: 0.5645 - val_loss: 0.0801 - val_accuracy: 0.5832\n",
            "Epoch 33/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0804 - accuracy: 0.5655 - val_loss: 0.0797 - val_accuracy: 0.5842\n",
            "Epoch 34/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0800 - accuracy: 0.5660 - val_loss: 0.0793 - val_accuracy: 0.5840\n",
            "Epoch 35/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0796 - accuracy: 0.5661 - val_loss: 0.0788 - val_accuracy: 0.5856\n",
            "Epoch 36/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0791 - accuracy: 0.5672 - val_loss: 0.0784 - val_accuracy: 0.5846\n",
            "Epoch 37/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0787 - accuracy: 0.5670 - val_loss: 0.0779 - val_accuracy: 0.5848\n",
            "Epoch 38/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0783 - accuracy: 0.5674 - val_loss: 0.0774 - val_accuracy: 0.5854\n",
            "Epoch 39/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0778 - accuracy: 0.5675 - val_loss: 0.0770 - val_accuracy: 0.5852\n",
            "Epoch 40/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0773 - accuracy: 0.5681 - val_loss: 0.0765 - val_accuracy: 0.5856\n",
            "Epoch 41/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0769 - accuracy: 0.5682 - val_loss: 0.0760 - val_accuracy: 0.5858\n",
            "Epoch 42/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0764 - accuracy: 0.5676 - val_loss: 0.0755 - val_accuracy: 0.5882\n",
            "Epoch 43/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0759 - accuracy: 0.5674 - val_loss: 0.0750 - val_accuracy: 0.5892\n",
            "Epoch 44/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0754 - accuracy: 0.5678 - val_loss: 0.0745 - val_accuracy: 0.5888\n",
            "Epoch 45/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0750 - accuracy: 0.5683 - val_loss: 0.0739 - val_accuracy: 0.5920\n",
            "Epoch 46/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0745 - accuracy: 0.5690 - val_loss: 0.0734 - val_accuracy: 0.5942\n",
            "Epoch 47/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0740 - accuracy: 0.5696 - val_loss: 0.0729 - val_accuracy: 0.5944\n",
            "Epoch 48/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0735 - accuracy: 0.5696 - val_loss: 0.0724 - val_accuracy: 0.5966\n",
            "Epoch 49/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0730 - accuracy: 0.5713 - val_loss: 0.0718 - val_accuracy: 0.5962\n",
            "Epoch 50/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0724 - accuracy: 0.5724 - val_loss: 0.0713 - val_accuracy: 0.5970\n",
            "Epoch 51/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0719 - accuracy: 0.5736 - val_loss: 0.0707 - val_accuracy: 0.5974\n",
            "Epoch 52/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0714 - accuracy: 0.5751 - val_loss: 0.0702 - val_accuracy: 0.6000\n",
            "Epoch 53/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0709 - accuracy: 0.5767 - val_loss: 0.0697 - val_accuracy: 0.6006\n",
            "Epoch 54/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0704 - accuracy: 0.5783 - val_loss: 0.0691 - val_accuracy: 0.6030\n",
            "Epoch 55/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0699 - accuracy: 0.5803 - val_loss: 0.0686 - val_accuracy: 0.6044\n",
            "Epoch 56/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0694 - accuracy: 0.5815 - val_loss: 0.0680 - val_accuracy: 0.6064\n",
            "Epoch 57/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0689 - accuracy: 0.5837 - val_loss: 0.0675 - val_accuracy: 0.6078\n",
            "Epoch 58/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0683 - accuracy: 0.5857 - val_loss: 0.0669 - val_accuracy: 0.6124\n",
            "Epoch 59/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0678 - accuracy: 0.5884 - val_loss: 0.0664 - val_accuracy: 0.6154\n",
            "Epoch 60/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0673 - accuracy: 0.5911 - val_loss: 0.0658 - val_accuracy: 0.6180\n",
            "Epoch 61/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0668 - accuracy: 0.5933 - val_loss: 0.0653 - val_accuracy: 0.6198\n",
            "Epoch 62/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0663 - accuracy: 0.5964 - val_loss: 0.0648 - val_accuracy: 0.6228\n",
            "Epoch 63/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0658 - accuracy: 0.5989 - val_loss: 0.0642 - val_accuracy: 0.6252\n",
            "Epoch 64/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0653 - accuracy: 0.6012 - val_loss: 0.0637 - val_accuracy: 0.6282\n",
            "Epoch 65/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0648 - accuracy: 0.6036 - val_loss: 0.0632 - val_accuracy: 0.6308\n",
            "Epoch 66/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0643 - accuracy: 0.6061 - val_loss: 0.0627 - val_accuracy: 0.6332\n",
            "Epoch 67/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0639 - accuracy: 0.6086 - val_loss: 0.0622 - val_accuracy: 0.6350\n",
            "Epoch 68/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0634 - accuracy: 0.6111 - val_loss: 0.0616 - val_accuracy: 0.6390\n",
            "Epoch 69/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0629 - accuracy: 0.6136 - val_loss: 0.0611 - val_accuracy: 0.6412\n",
            "Epoch 70/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0624 - accuracy: 0.6164 - val_loss: 0.0606 - val_accuracy: 0.6444\n",
            "Epoch 71/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0620 - accuracy: 0.6193 - val_loss: 0.0601 - val_accuracy: 0.6468\n",
            "Epoch 72/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0615 - accuracy: 0.6222 - val_loss: 0.0597 - val_accuracy: 0.6502\n",
            "Epoch 73/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0611 - accuracy: 0.6252 - val_loss: 0.0592 - val_accuracy: 0.6520\n",
            "Epoch 74/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0606 - accuracy: 0.6277 - val_loss: 0.0587 - val_accuracy: 0.6542\n",
            "Epoch 75/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0602 - accuracy: 0.6305 - val_loss: 0.0582 - val_accuracy: 0.6568\n",
            "Epoch 76/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0597 - accuracy: 0.6330 - val_loss: 0.0578 - val_accuracy: 0.6592\n",
            "Epoch 77/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0593 - accuracy: 0.6358 - val_loss: 0.0573 - val_accuracy: 0.6618\n",
            "Epoch 78/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0589 - accuracy: 0.6383 - val_loss: 0.0568 - val_accuracy: 0.6630\n",
            "Epoch 79/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0585 - accuracy: 0.6409 - val_loss: 0.0564 - val_accuracy: 0.6648\n",
            "Epoch 80/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0581 - accuracy: 0.6441 - val_loss: 0.0559 - val_accuracy: 0.6700\n",
            "Epoch 81/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0576 - accuracy: 0.6471 - val_loss: 0.0555 - val_accuracy: 0.6734\n",
            "Epoch 82/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0572 - accuracy: 0.6497 - val_loss: 0.0551 - val_accuracy: 0.6760\n",
            "Epoch 83/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0568 - accuracy: 0.6524 - val_loss: 0.0546 - val_accuracy: 0.6792\n",
            "Epoch 84/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0564 - accuracy: 0.6555 - val_loss: 0.0542 - val_accuracy: 0.6830\n",
            "Epoch 85/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0561 - accuracy: 0.6584 - val_loss: 0.0538 - val_accuracy: 0.6862\n",
            "Epoch 86/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0557 - accuracy: 0.6615 - val_loss: 0.0534 - val_accuracy: 0.6902\n",
            "Epoch 87/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0553 - accuracy: 0.6647 - val_loss: 0.0530 - val_accuracy: 0.6948\n",
            "Epoch 88/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0549 - accuracy: 0.6673 - val_loss: 0.0526 - val_accuracy: 0.6986\n",
            "Epoch 89/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0546 - accuracy: 0.6703 - val_loss: 0.0522 - val_accuracy: 0.7026\n",
            "Epoch 90/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0542 - accuracy: 0.6736 - val_loss: 0.0518 - val_accuracy: 0.7066\n",
            "Epoch 91/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0538 - accuracy: 0.6769 - val_loss: 0.0514 - val_accuracy: 0.7110\n",
            "Epoch 92/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0535 - accuracy: 0.6793 - val_loss: 0.0510 - val_accuracy: 0.7152\n",
            "Epoch 93/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0531 - accuracy: 0.6826 - val_loss: 0.0507 - val_accuracy: 0.7178\n",
            "Epoch 94/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0528 - accuracy: 0.6855 - val_loss: 0.0503 - val_accuracy: 0.7208\n",
            "Epoch 95/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0524 - accuracy: 0.6883 - val_loss: 0.0499 - val_accuracy: 0.7236\n",
            "Epoch 96/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0521 - accuracy: 0.6911 - val_loss: 0.0496 - val_accuracy: 0.7270\n",
            "Epoch 97/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0518 - accuracy: 0.6941 - val_loss: 0.0492 - val_accuracy: 0.7304\n",
            "Epoch 98/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0514 - accuracy: 0.6976 - val_loss: 0.0489 - val_accuracy: 0.7336\n",
            "Epoch 99/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0511 - accuracy: 0.7007 - val_loss: 0.0485 - val_accuracy: 0.7360\n",
            "Epoch 100/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0508 - accuracy: 0.7028 - val_loss: 0.0482 - val_accuracy: 0.7394\n",
            "Epoch 101/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0505 - accuracy: 0.7051 - val_loss: 0.0478 - val_accuracy: 0.7424\n",
            "Epoch 102/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0502 - accuracy: 0.7078 - val_loss: 0.0475 - val_accuracy: 0.7442\n",
            "Epoch 103/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0499 - accuracy: 0.7109 - val_loss: 0.0472 - val_accuracy: 0.7480\n",
            "Epoch 104/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0496 - accuracy: 0.7128 - val_loss: 0.0468 - val_accuracy: 0.7496\n",
            "Epoch 105/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0493 - accuracy: 0.7161 - val_loss: 0.0465 - val_accuracy: 0.7510\n",
            "Epoch 106/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0490 - accuracy: 0.7186 - val_loss: 0.0462 - val_accuracy: 0.7534\n",
            "Epoch 107/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0487 - accuracy: 0.7212 - val_loss: 0.0459 - val_accuracy: 0.7556\n",
            "Epoch 108/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0484 - accuracy: 0.7235 - val_loss: 0.0456 - val_accuracy: 0.7584\n",
            "Epoch 109/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0481 - accuracy: 0.7260 - val_loss: 0.0453 - val_accuracy: 0.7608\n",
            "Epoch 110/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0478 - accuracy: 0.7284 - val_loss: 0.0450 - val_accuracy: 0.7624\n",
            "Epoch 111/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0475 - accuracy: 0.7304 - val_loss: 0.0447 - val_accuracy: 0.7644\n",
            "Epoch 112/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0472 - accuracy: 0.7330 - val_loss: 0.0444 - val_accuracy: 0.7672\n",
            "Epoch 113/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0470 - accuracy: 0.7348 - val_loss: 0.0441 - val_accuracy: 0.7670\n",
            "Epoch 114/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0467 - accuracy: 0.7367 - val_loss: 0.0438 - val_accuracy: 0.7684\n",
            "Epoch 115/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0464 - accuracy: 0.7381 - val_loss: 0.0435 - val_accuracy: 0.7704\n",
            "Epoch 116/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0462 - accuracy: 0.7396 - val_loss: 0.0432 - val_accuracy: 0.7732\n",
            "Epoch 117/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0459 - accuracy: 0.7419 - val_loss: 0.0429 - val_accuracy: 0.7756\n",
            "Epoch 118/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0456 - accuracy: 0.7437 - val_loss: 0.0426 - val_accuracy: 0.7782\n",
            "Epoch 119/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0454 - accuracy: 0.7453 - val_loss: 0.0424 - val_accuracy: 0.7798\n",
            "Epoch 120/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0451 - accuracy: 0.7471 - val_loss: 0.0421 - val_accuracy: 0.7802\n",
            "Epoch 121/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0449 - accuracy: 0.7484 - val_loss: 0.0418 - val_accuracy: 0.7828\n",
            "Epoch 122/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0446 - accuracy: 0.7502 - val_loss: 0.0415 - val_accuracy: 0.7846\n",
            "Epoch 123/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0444 - accuracy: 0.7516 - val_loss: 0.0413 - val_accuracy: 0.7850\n",
            "Epoch 124/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0441 - accuracy: 0.7533 - val_loss: 0.0410 - val_accuracy: 0.7860\n",
            "Epoch 125/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0439 - accuracy: 0.7541 - val_loss: 0.0408 - val_accuracy: 0.7890\n",
            "Epoch 126/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0437 - accuracy: 0.7557 - val_loss: 0.0405 - val_accuracy: 0.7902\n",
            "Epoch 127/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0434 - accuracy: 0.7570 - val_loss: 0.0403 - val_accuracy: 0.7914\n",
            "Epoch 128/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0432 - accuracy: 0.7580 - val_loss: 0.0400 - val_accuracy: 0.7926\n",
            "Epoch 129/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0430 - accuracy: 0.7595 - val_loss: 0.0398 - val_accuracy: 0.7938\n",
            "Epoch 130/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0427 - accuracy: 0.7608 - val_loss: 0.0395 - val_accuracy: 0.7954\n",
            "Epoch 131/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0425 - accuracy: 0.7619 - val_loss: 0.0393 - val_accuracy: 0.7970\n",
            "Epoch 132/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0423 - accuracy: 0.7630 - val_loss: 0.0390 - val_accuracy: 0.7978\n",
            "Epoch 133/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0421 - accuracy: 0.7640 - val_loss: 0.0388 - val_accuracy: 0.7994\n",
            "Epoch 134/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0418 - accuracy: 0.7652 - val_loss: 0.0385 - val_accuracy: 0.8002\n",
            "Epoch 135/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0416 - accuracy: 0.7666 - val_loss: 0.0383 - val_accuracy: 0.8014\n",
            "Epoch 136/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0414 - accuracy: 0.7675 - val_loss: 0.0381 - val_accuracy: 0.8022\n",
            "Epoch 137/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0412 - accuracy: 0.7686 - val_loss: 0.0378 - val_accuracy: 0.8040\n",
            "Epoch 138/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0410 - accuracy: 0.7698 - val_loss: 0.0376 - val_accuracy: 0.8054\n",
            "Epoch 139/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0408 - accuracy: 0.7713 - val_loss: 0.0374 - val_accuracy: 0.8062\n",
            "Epoch 140/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0406 - accuracy: 0.7726 - val_loss: 0.0372 - val_accuracy: 0.8076\n",
            "Epoch 141/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0404 - accuracy: 0.7737 - val_loss: 0.0369 - val_accuracy: 0.8084\n",
            "Epoch 142/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0402 - accuracy: 0.7751 - val_loss: 0.0367 - val_accuracy: 0.8108\n",
            "Epoch 143/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0400 - accuracy: 0.7765 - val_loss: 0.0365 - val_accuracy: 0.8120\n",
            "Epoch 144/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0398 - accuracy: 0.7777 - val_loss: 0.0363 - val_accuracy: 0.8128\n",
            "Epoch 145/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0396 - accuracy: 0.7793 - val_loss: 0.0361 - val_accuracy: 0.8148\n",
            "Epoch 146/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0394 - accuracy: 0.7807 - val_loss: 0.0359 - val_accuracy: 0.8162\n",
            "Epoch 147/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0392 - accuracy: 0.7818 - val_loss: 0.0356 - val_accuracy: 0.8176\n",
            "Epoch 148/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0390 - accuracy: 0.7832 - val_loss: 0.0354 - val_accuracy: 0.8196\n",
            "Epoch 149/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0388 - accuracy: 0.7843 - val_loss: 0.0352 - val_accuracy: 0.8206\n",
            "Epoch 150/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0386 - accuracy: 0.7858 - val_loss: 0.0350 - val_accuracy: 0.8232\n",
            "Epoch 151/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0384 - accuracy: 0.7874 - val_loss: 0.0348 - val_accuracy: 0.8246\n",
            "Epoch 152/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0382 - accuracy: 0.7887 - val_loss: 0.0346 - val_accuracy: 0.8260\n",
            "Epoch 153/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0380 - accuracy: 0.7898 - val_loss: 0.0344 - val_accuracy: 0.8272\n",
            "Epoch 154/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0378 - accuracy: 0.7912 - val_loss: 0.0342 - val_accuracy: 0.8292\n",
            "Epoch 155/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0377 - accuracy: 0.7930 - val_loss: 0.0340 - val_accuracy: 0.8312\n",
            "Epoch 156/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0375 - accuracy: 0.7940 - val_loss: 0.0338 - val_accuracy: 0.8320\n",
            "Epoch 157/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0373 - accuracy: 0.7954 - val_loss: 0.0336 - val_accuracy: 0.8336\n",
            "Epoch 158/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0371 - accuracy: 0.7969 - val_loss: 0.0334 - val_accuracy: 0.8344\n",
            "Epoch 159/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0370 - accuracy: 0.7984 - val_loss: 0.0332 - val_accuracy: 0.8362\n",
            "Epoch 160/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0368 - accuracy: 0.7996 - val_loss: 0.0331 - val_accuracy: 0.8380\n",
            "Epoch 161/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0366 - accuracy: 0.8012 - val_loss: 0.0329 - val_accuracy: 0.8398\n",
            "Epoch 162/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0364 - accuracy: 0.8023 - val_loss: 0.0327 - val_accuracy: 0.8412\n",
            "Epoch 163/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0363 - accuracy: 0.8037 - val_loss: 0.0325 - val_accuracy: 0.8432\n",
            "Epoch 164/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0361 - accuracy: 0.8052 - val_loss: 0.0323 - val_accuracy: 0.8450\n",
            "Epoch 165/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0359 - accuracy: 0.8062 - val_loss: 0.0321 - val_accuracy: 0.8472\n",
            "Epoch 166/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0358 - accuracy: 0.8081 - val_loss: 0.0320 - val_accuracy: 0.8482\n",
            "Epoch 167/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0356 - accuracy: 0.8096 - val_loss: 0.0318 - val_accuracy: 0.8494\n",
            "Epoch 168/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0354 - accuracy: 0.8110 - val_loss: 0.0316 - val_accuracy: 0.8512\n",
            "Epoch 169/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0353 - accuracy: 0.8124 - val_loss: 0.0314 - val_accuracy: 0.8526\n",
            "Epoch 170/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0351 - accuracy: 0.8138 - val_loss: 0.0313 - val_accuracy: 0.8542\n",
            "Epoch 171/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0350 - accuracy: 0.8150 - val_loss: 0.0311 - val_accuracy: 0.8562\n",
            "Epoch 172/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0348 - accuracy: 0.8163 - val_loss: 0.0309 - val_accuracy: 0.8570\n",
            "Epoch 173/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0346 - accuracy: 0.8175 - val_loss: 0.0307 - val_accuracy: 0.8588\n",
            "Epoch 174/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0345 - accuracy: 0.8185 - val_loss: 0.0306 - val_accuracy: 0.8600\n",
            "Epoch 175/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0343 - accuracy: 0.8199 - val_loss: 0.0304 - val_accuracy: 0.8614\n",
            "Epoch 176/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0342 - accuracy: 0.8214 - val_loss: 0.0303 - val_accuracy: 0.8626\n",
            "Epoch 177/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0340 - accuracy: 0.8226 - val_loss: 0.0301 - val_accuracy: 0.8642\n",
            "Epoch 178/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0339 - accuracy: 0.8237 - val_loss: 0.0299 - val_accuracy: 0.8652\n",
            "Epoch 179/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0337 - accuracy: 0.8251 - val_loss: 0.0298 - val_accuracy: 0.8666\n",
            "Epoch 180/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0336 - accuracy: 0.8258 - val_loss: 0.0296 - val_accuracy: 0.8676\n",
            "Epoch 181/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0334 - accuracy: 0.8270 - val_loss: 0.0295 - val_accuracy: 0.8676\n",
            "Epoch 182/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0333 - accuracy: 0.8282 - val_loss: 0.0293 - val_accuracy: 0.8686\n",
            "Epoch 183/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0332 - accuracy: 0.8294 - val_loss: 0.0292 - val_accuracy: 0.8688\n",
            "Epoch 184/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0330 - accuracy: 0.8301 - val_loss: 0.0290 - val_accuracy: 0.8694\n",
            "Epoch 185/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0329 - accuracy: 0.8312 - val_loss: 0.0288 - val_accuracy: 0.8698\n",
            "Epoch 186/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0327 - accuracy: 0.8324 - val_loss: 0.0287 - val_accuracy: 0.8710\n",
            "Epoch 187/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0326 - accuracy: 0.8335 - val_loss: 0.0286 - val_accuracy: 0.8726\n",
            "Epoch 188/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0325 - accuracy: 0.8344 - val_loss: 0.0284 - val_accuracy: 0.8724\n",
            "Epoch 189/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0323 - accuracy: 0.8354 - val_loss: 0.0283 - val_accuracy: 0.8740\n",
            "Epoch 190/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0322 - accuracy: 0.8359 - val_loss: 0.0281 - val_accuracy: 0.8746\n",
            "Epoch 191/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0321 - accuracy: 0.8371 - val_loss: 0.0280 - val_accuracy: 0.8760\n",
            "Epoch 192/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0319 - accuracy: 0.8380 - val_loss: 0.0278 - val_accuracy: 0.8768\n",
            "Epoch 193/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0318 - accuracy: 0.8389 - val_loss: 0.0277 - val_accuracy: 0.8782\n",
            "Epoch 194/200\n",
            "430/430 [==============================] - 1s 2ms/step - loss: 0.0317 - accuracy: 0.8398 - val_loss: 0.0276 - val_accuracy: 0.8790\n",
            "Epoch 195/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0315 - accuracy: 0.8407 - val_loss: 0.0274 - val_accuracy: 0.8804\n",
            "Epoch 196/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0314 - accuracy: 0.8417 - val_loss: 0.0273 - val_accuracy: 0.8824\n",
            "Epoch 197/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0313 - accuracy: 0.8423 - val_loss: 0.0272 - val_accuracy: 0.8834\n",
            "Epoch 198/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0312 - accuracy: 0.8432 - val_loss: 0.0270 - val_accuracy: 0.8836\n",
            "Epoch 199/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0310 - accuracy: 0.8440 - val_loss: 0.0269 - val_accuracy: 0.8846\n",
            "Epoch 200/200\n",
            "430/430 [==============================] - 1s 3ms/step - loss: 0.0309 - accuracy: 0.8448 - val_loss: 0.0268 - val_accuracy: 0.8852\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f092f09b110>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzkmBQrZ91zN"
      },
      "source": [
        "### 신경망 모델 정확도 평가 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucTO8Nx4xHxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d19b587-09ca-4024-900c-991b1396bb6b"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.0296 - accuracy: 0.8579\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.029609331861138344, 0.8579000234603882]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIMv2pP2xHxS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9b09fde-9273-41e4-bf10-1179903a4d7b"
      },
      "source": [
        "n = 10\n",
        "pred = model.predict(X_test[n].reshape(-1, 784))\n",
        "print(pred)\n",
        "print(np.argmax(pred))\n",
        "print(y_test[n])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.7974252  0.00115562 0.03129882 0.03014045 0.00414175 0.0935775\n",
            "  0.00691651 0.00346909 0.03035255 0.00152245]]\n",
            "0\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    }
  ]
}