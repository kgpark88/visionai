{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "mnist_ann.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy_eNWXjxHxG"
      },
      "source": [
        "# MNINST 분류기 - ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TN9Tj7QxHxI"
      },
      "source": [
        "### 라이브러리 임포트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1KIo7RPxHxI"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enZ5oTJC215S",
        "outputId": "888fdd69-db37-4d21-99fb-bf468cddb815"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIZOoeJdxHxJ"
      },
      "source": [
        "#### MNIST 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "qGj5Yh_zxHxK"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-nRc0oTzlfe"
      },
      "source": [
        "### MNIST 데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10PquKSxxHxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2bd1e39-4840-48ae-bc60-69625b74862b"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkPd8d1TxHxL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d62a56ab-ed60-4d6a-f9d8-b31b3e7b70ea"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4KycfPOxHxN"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29qKimW6xHxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fde22ff-ef4c-49c1-ed20-1b7a34a1ac0f"
      },
      "source": [
        "y_train[0:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "givkTlyZxHxN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "0cfe7034-852f-496f-9be7-cfb2e96db8c9"
      },
      "source": [
        "plt.imshow(X_train[0], cmap='Greys')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdabaec9590>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc485XkvxHxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9071baa-861f-4c69-9546-0e400f2cd8fa"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI2Pomf2xHxO"
      },
      "source": [
        "### 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2d1svE-0CTA"
      },
      "source": [
        "신경망의 입력층과 출력층의 크기에 맞도록 데이터의 크기를 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P34mv84hxHxO"
      },
      "source": [
        "X_train = X_train.reshape(60000, 784).astype('float32')\n",
        "X_valid = X_valid.reshape(10000, 784).astype('float32')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dye9Rrv0TMI"
      },
      "source": [
        "데이터 정규화 : 입력값을 0과 1사이의 범위로 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1aIBfgY4yUH",
        "outputId": "d37690f5-cd50-404b-ec97-902914b53944"
      },
      "source": [
        "1/255.0"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00392156862745098"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWMc4UZmxHxP"
      },
      "source": [
        "X_train /= 255\n",
        "X_valid /= 255"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlhxNm-nxHxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ecfb53f-b2d1-4336-e57f-5183ed1ee79b"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
              "       0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
              "       0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n",
              "       0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n",
              "       0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n",
              "       0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n",
              "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n",
              "       0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
              "       0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.54509807,\n",
              "       0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n",
              "       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n",
              "       0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n",
              "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
              "       0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n",
              "       0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n",
              "       0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n",
              "       0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
              "       0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n",
              "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n",
              "       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n",
              "       0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFrYpRkP0gTn"
      },
      "source": [
        "레이블을 원핫 인코딩으로 바꾸기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUlPjR8IxHxP"
      },
      "source": [
        "n_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
        "y_valid = keras.utils.to_categorical(y_valid, n_classes)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sKy7YomxHxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a728aa3f-cebf-4f8e-8cd2-e41a53be2315"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uCfvSbTxHxQ"
      },
      "source": [
        "### 신경망 구조 설계"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zO9xNfkxHxQ"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, activation='sigmoid', input_shape=(784,)))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f5bfv04xHxQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c3425ba-ae58-4eba-b852-cab1d8503fd3"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpyhpGsCxHxQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77ffa488-2ffd-4524-b8cf-64c66b32354f"
      },
      "source": [
        "(784*64) + 64"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50240"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyDRiY3OxHxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36baa123-8165-4639-cef7-09aadeb65f0b"
      },
      "source": [
        "(64*10) + 10"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "650"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCr6fKAUxHxR"
      },
      "source": [
        "### 신경망 모델 컴파일"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wh-sD2SxHxR"
      },
      "source": [
        "model.compile(loss='mean_squared_error', \n",
        "              optimizer=SGD(learning_rate=0.01), \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4Ebh8sTxHxR"
      },
      "source": [
        "### 신경망 모델 훈련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQXDUkYBxHxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2990b4a5-151d-4192-a69a-49754c039ad4"
      },
      "source": [
        "model.fit(X_train, y_train, \n",
        "          batch_size=128, \n",
        "          epochs=200, \n",
        "          verbose=1, \n",
        "          validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0923 - accuracy: 0.0986 - val_loss: 0.0915 - val_accuracy: 0.0978\n",
            "Epoch 2/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0910 - accuracy: 0.1003 - val_loss: 0.0906 - val_accuracy: 0.1024\n",
            "Epoch 3/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0903 - accuracy: 0.1055 - val_loss: 0.0901 - val_accuracy: 0.1128\n",
            "Epoch 4/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0899 - accuracy: 0.1160 - val_loss: 0.0897 - val_accuracy: 0.1253\n",
            "Epoch 5/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0895 - accuracy: 0.1315 - val_loss: 0.0894 - val_accuracy: 0.1447\n",
            "Epoch 6/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0892 - accuracy: 0.1551 - val_loss: 0.0891 - val_accuracy: 0.1704\n",
            "Epoch 7/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0890 - accuracy: 0.1839 - val_loss: 0.0888 - val_accuracy: 0.2055\n",
            "Epoch 8/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0887 - accuracy: 0.2236 - val_loss: 0.0886 - val_accuracy: 0.2449\n",
            "Epoch 9/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0884 - accuracy: 0.2614 - val_loss: 0.0883 - val_accuracy: 0.2820\n",
            "Epoch 10/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0882 - accuracy: 0.2946 - val_loss: 0.0880 - val_accuracy: 0.3143\n",
            "Epoch 11/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0879 - accuracy: 0.3212 - val_loss: 0.0878 - val_accuracy: 0.3393\n",
            "Epoch 12/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0876 - accuracy: 0.3406 - val_loss: 0.0875 - val_accuracy: 0.3583\n",
            "Epoch 13/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0874 - accuracy: 0.3553 - val_loss: 0.0872 - val_accuracy: 0.3723\n",
            "Epoch 14/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0871 - accuracy: 0.3681 - val_loss: 0.0869 - val_accuracy: 0.3860\n",
            "Epoch 15/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0868 - accuracy: 0.3813 - val_loss: 0.0867 - val_accuracy: 0.3964\n",
            "Epoch 16/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0865 - accuracy: 0.3891 - val_loss: 0.0864 - val_accuracy: 0.4047\n",
            "Epoch 17/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0862 - accuracy: 0.3973 - val_loss: 0.0861 - val_accuracy: 0.4101\n",
            "Epoch 18/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0859 - accuracy: 0.4050 - val_loss: 0.0857 - val_accuracy: 0.4147\n",
            "Epoch 19/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0856 - accuracy: 0.4103 - val_loss: 0.0854 - val_accuracy: 0.4200\n",
            "Epoch 20/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0853 - accuracy: 0.4162 - val_loss: 0.0851 - val_accuracy: 0.4231\n",
            "Epoch 21/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0850 - accuracy: 0.4205 - val_loss: 0.0848 - val_accuracy: 0.4267\n",
            "Epoch 22/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0846 - accuracy: 0.4249 - val_loss: 0.0844 - val_accuracy: 0.4312\n",
            "Epoch 23/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0843 - accuracy: 0.4301 - val_loss: 0.0841 - val_accuracy: 0.4349\n",
            "Epoch 24/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0840 - accuracy: 0.4322 - val_loss: 0.0837 - val_accuracy: 0.4383\n",
            "Epoch 25/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0836 - accuracy: 0.4372 - val_loss: 0.0834 - val_accuracy: 0.4416\n",
            "Epoch 26/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0832 - accuracy: 0.4386 - val_loss: 0.0830 - val_accuracy: 0.4446\n",
            "Epoch 27/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0829 - accuracy: 0.4424 - val_loss: 0.0826 - val_accuracy: 0.4481\n",
            "Epoch 28/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0825 - accuracy: 0.4469 - val_loss: 0.0822 - val_accuracy: 0.4520\n",
            "Epoch 29/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0821 - accuracy: 0.4506 - val_loss: 0.0818 - val_accuracy: 0.4546\n",
            "Epoch 30/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0817 - accuracy: 0.4538 - val_loss: 0.0814 - val_accuracy: 0.4579\n",
            "Epoch 31/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0813 - accuracy: 0.4569 - val_loss: 0.0810 - val_accuracy: 0.4613\n",
            "Epoch 32/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0809 - accuracy: 0.4618 - val_loss: 0.0806 - val_accuracy: 0.4651\n",
            "Epoch 33/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0804 - accuracy: 0.4658 - val_loss: 0.0801 - val_accuracy: 0.4688\n",
            "Epoch 34/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0800 - accuracy: 0.4715 - val_loss: 0.0797 - val_accuracy: 0.4734\n",
            "Epoch 35/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0796 - accuracy: 0.4766 - val_loss: 0.0793 - val_accuracy: 0.4790\n",
            "Epoch 36/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0791 - accuracy: 0.4819 - val_loss: 0.0788 - val_accuracy: 0.4836\n",
            "Epoch 37/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0787 - accuracy: 0.4866 - val_loss: 0.0784 - val_accuracy: 0.4896\n",
            "Epoch 38/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0782 - accuracy: 0.4920 - val_loss: 0.0779 - val_accuracy: 0.4936\n",
            "Epoch 39/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0778 - accuracy: 0.4974 - val_loss: 0.0774 - val_accuracy: 0.4994\n",
            "Epoch 40/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0773 - accuracy: 0.5019 - val_loss: 0.0770 - val_accuracy: 0.5053\n",
            "Epoch 41/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0769 - accuracy: 0.5078 - val_loss: 0.0765 - val_accuracy: 0.5100\n",
            "Epoch 42/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0764 - accuracy: 0.5131 - val_loss: 0.0760 - val_accuracy: 0.5151\n",
            "Epoch 43/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0759 - accuracy: 0.5179 - val_loss: 0.0755 - val_accuracy: 0.5201\n",
            "Epoch 44/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0754 - accuracy: 0.5238 - val_loss: 0.0750 - val_accuracy: 0.5257\n",
            "Epoch 45/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0750 - accuracy: 0.5296 - val_loss: 0.0745 - val_accuracy: 0.5309\n",
            "Epoch 46/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0745 - accuracy: 0.5349 - val_loss: 0.0741 - val_accuracy: 0.5368\n",
            "Epoch 47/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0740 - accuracy: 0.5397 - val_loss: 0.0736 - val_accuracy: 0.5429\n",
            "Epoch 48/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0735 - accuracy: 0.5457 - val_loss: 0.0731 - val_accuracy: 0.5476\n",
            "Epoch 49/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0730 - accuracy: 0.5512 - val_loss: 0.0726 - val_accuracy: 0.5530\n",
            "Epoch 50/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0725 - accuracy: 0.5564 - val_loss: 0.0721 - val_accuracy: 0.5582\n",
            "Epoch 51/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0720 - accuracy: 0.5612 - val_loss: 0.0716 - val_accuracy: 0.5633\n",
            "Epoch 52/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0715 - accuracy: 0.5658 - val_loss: 0.0711 - val_accuracy: 0.5677\n",
            "Epoch 53/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0710 - accuracy: 0.5712 - val_loss: 0.0706 - val_accuracy: 0.5737\n",
            "Epoch 54/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0705 - accuracy: 0.5769 - val_loss: 0.0701 - val_accuracy: 0.5790\n",
            "Epoch 55/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0700 - accuracy: 0.5811 - val_loss: 0.0695 - val_accuracy: 0.5840\n",
            "Epoch 56/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0695 - accuracy: 0.5858 - val_loss: 0.0690 - val_accuracy: 0.5878\n",
            "Epoch 57/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0690 - accuracy: 0.5894 - val_loss: 0.0685 - val_accuracy: 0.5920\n",
            "Epoch 58/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0685 - accuracy: 0.5945 - val_loss: 0.0680 - val_accuracy: 0.5960\n",
            "Epoch 59/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0680 - accuracy: 0.5980 - val_loss: 0.0675 - val_accuracy: 0.6011\n",
            "Epoch 60/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0675 - accuracy: 0.6026 - val_loss: 0.0670 - val_accuracy: 0.6039\n",
            "Epoch 61/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0670 - accuracy: 0.6058 - val_loss: 0.0665 - val_accuracy: 0.6072\n",
            "Epoch 62/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0665 - accuracy: 0.6094 - val_loss: 0.0660 - val_accuracy: 0.6113\n",
            "Epoch 63/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0660 - accuracy: 0.6130 - val_loss: 0.0655 - val_accuracy: 0.6142\n",
            "Epoch 64/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0655 - accuracy: 0.6159 - val_loss: 0.0650 - val_accuracy: 0.6172\n",
            "Epoch 65/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0651 - accuracy: 0.6184 - val_loss: 0.0645 - val_accuracy: 0.6208\n",
            "Epoch 66/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0646 - accuracy: 0.6222 - val_loss: 0.0640 - val_accuracy: 0.6253\n",
            "Epoch 67/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0641 - accuracy: 0.6253 - val_loss: 0.0635 - val_accuracy: 0.6276\n",
            "Epoch 68/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0636 - accuracy: 0.6283 - val_loss: 0.0630 - val_accuracy: 0.6313\n",
            "Epoch 69/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0631 - accuracy: 0.6316 - val_loss: 0.0625 - val_accuracy: 0.6347\n",
            "Epoch 70/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0626 - accuracy: 0.6346 - val_loss: 0.0620 - val_accuracy: 0.6379\n",
            "Epoch 71/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0621 - accuracy: 0.6378 - val_loss: 0.0615 - val_accuracy: 0.6413\n",
            "Epoch 72/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0616 - accuracy: 0.6415 - val_loss: 0.0610 - val_accuracy: 0.6446\n",
            "Epoch 73/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0612 - accuracy: 0.6443 - val_loss: 0.0605 - val_accuracy: 0.6481\n",
            "Epoch 74/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0607 - accuracy: 0.6472 - val_loss: 0.0601 - val_accuracy: 0.6519\n",
            "Epoch 75/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0602 - accuracy: 0.6509 - val_loss: 0.0596 - val_accuracy: 0.6552\n",
            "Epoch 76/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0597 - accuracy: 0.6539 - val_loss: 0.0591 - val_accuracy: 0.6573\n",
            "Epoch 77/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0593 - accuracy: 0.6568 - val_loss: 0.0586 - val_accuracy: 0.6600\n",
            "Epoch 78/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0588 - accuracy: 0.6601 - val_loss: 0.0582 - val_accuracy: 0.6635\n",
            "Epoch 79/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0584 - accuracy: 0.6631 - val_loss: 0.0577 - val_accuracy: 0.6667\n",
            "Epoch 80/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0579 - accuracy: 0.6660 - val_loss: 0.0573 - val_accuracy: 0.6709\n",
            "Epoch 81/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0575 - accuracy: 0.6689 - val_loss: 0.0568 - val_accuracy: 0.6745\n",
            "Epoch 82/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0570 - accuracy: 0.6729 - val_loss: 0.0564 - val_accuracy: 0.6774\n",
            "Epoch 83/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0566 - accuracy: 0.6763 - val_loss: 0.0559 - val_accuracy: 0.6808\n",
            "Epoch 84/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0561 - accuracy: 0.6790 - val_loss: 0.0555 - val_accuracy: 0.6846\n",
            "Epoch 85/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0557 - accuracy: 0.6820 - val_loss: 0.0550 - val_accuracy: 0.6883\n",
            "Epoch 86/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0553 - accuracy: 0.6855 - val_loss: 0.0546 - val_accuracy: 0.6917\n",
            "Epoch 87/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0549 - accuracy: 0.6883 - val_loss: 0.0542 - val_accuracy: 0.6948\n",
            "Epoch 88/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0544 - accuracy: 0.6913 - val_loss: 0.0538 - val_accuracy: 0.6983\n",
            "Epoch 89/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0540 - accuracy: 0.6948 - val_loss: 0.0533 - val_accuracy: 0.7031\n",
            "Epoch 90/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0536 - accuracy: 0.6980 - val_loss: 0.0529 - val_accuracy: 0.7055\n",
            "Epoch 91/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0532 - accuracy: 0.7005 - val_loss: 0.0525 - val_accuracy: 0.7103\n",
            "Epoch 92/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0528 - accuracy: 0.7037 - val_loss: 0.0521 - val_accuracy: 0.7140\n",
            "Epoch 93/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0524 - accuracy: 0.7061 - val_loss: 0.0517 - val_accuracy: 0.7176\n",
            "Epoch 94/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0520 - accuracy: 0.7096 - val_loss: 0.0513 - val_accuracy: 0.7199\n",
            "Epoch 95/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0516 - accuracy: 0.7126 - val_loss: 0.0509 - val_accuracy: 0.7234\n",
            "Epoch 96/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0512 - accuracy: 0.7159 - val_loss: 0.0505 - val_accuracy: 0.7259\n",
            "Epoch 97/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0509 - accuracy: 0.7190 - val_loss: 0.0501 - val_accuracy: 0.7283\n",
            "Epoch 98/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0505 - accuracy: 0.7214 - val_loss: 0.0498 - val_accuracy: 0.7308\n",
            "Epoch 99/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0501 - accuracy: 0.7242 - val_loss: 0.0494 - val_accuracy: 0.7343\n",
            "Epoch 100/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0498 - accuracy: 0.7269 - val_loss: 0.0490 - val_accuracy: 0.7363\n",
            "Epoch 101/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0494 - accuracy: 0.7297 - val_loss: 0.0487 - val_accuracy: 0.7396\n",
            "Epoch 102/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0490 - accuracy: 0.7321 - val_loss: 0.0483 - val_accuracy: 0.7419\n",
            "Epoch 103/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0487 - accuracy: 0.7344 - val_loss: 0.0479 - val_accuracy: 0.7444\n",
            "Epoch 104/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0483 - accuracy: 0.7366 - val_loss: 0.0476 - val_accuracy: 0.7469\n",
            "Epoch 105/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0480 - accuracy: 0.7390 - val_loss: 0.0473 - val_accuracy: 0.7488\n",
            "Epoch 106/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0477 - accuracy: 0.7411 - val_loss: 0.0469 - val_accuracy: 0.7507\n",
            "Epoch 107/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0473 - accuracy: 0.7427 - val_loss: 0.0466 - val_accuracy: 0.7539\n",
            "Epoch 108/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0470 - accuracy: 0.7442 - val_loss: 0.0462 - val_accuracy: 0.7548\n",
            "Epoch 109/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0467 - accuracy: 0.7470 - val_loss: 0.0459 - val_accuracy: 0.7566\n",
            "Epoch 110/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0463 - accuracy: 0.7484 - val_loss: 0.0456 - val_accuracy: 0.7580\n",
            "Epoch 111/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0460 - accuracy: 0.7505 - val_loss: 0.0453 - val_accuracy: 0.7594\n",
            "Epoch 112/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0457 - accuracy: 0.7523 - val_loss: 0.0449 - val_accuracy: 0.7607\n",
            "Epoch 113/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0454 - accuracy: 0.7543 - val_loss: 0.0446 - val_accuracy: 0.7627\n",
            "Epoch 114/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0451 - accuracy: 0.7559 - val_loss: 0.0443 - val_accuracy: 0.7637\n",
            "Epoch 115/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0448 - accuracy: 0.7580 - val_loss: 0.0440 - val_accuracy: 0.7652\n",
            "Epoch 116/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0445 - accuracy: 0.7595 - val_loss: 0.0437 - val_accuracy: 0.7675\n",
            "Epoch 117/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0442 - accuracy: 0.7614 - val_loss: 0.0434 - val_accuracy: 0.7690\n",
            "Epoch 118/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0439 - accuracy: 0.7629 - val_loss: 0.0431 - val_accuracy: 0.7712\n",
            "Epoch 119/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0436 - accuracy: 0.7646 - val_loss: 0.0428 - val_accuracy: 0.7726\n",
            "Epoch 120/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0433 - accuracy: 0.7660 - val_loss: 0.0425 - val_accuracy: 0.7750\n",
            "Epoch 121/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0430 - accuracy: 0.7680 - val_loss: 0.0422 - val_accuracy: 0.7764\n",
            "Epoch 122/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0427 - accuracy: 0.7695 - val_loss: 0.0420 - val_accuracy: 0.7781\n",
            "Epoch 123/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0425 - accuracy: 0.7707 - val_loss: 0.0417 - val_accuracy: 0.7803\n",
            "Epoch 124/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0422 - accuracy: 0.7726 - val_loss: 0.0414 - val_accuracy: 0.7820\n",
            "Epoch 125/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0419 - accuracy: 0.7744 - val_loss: 0.0411 - val_accuracy: 0.7828\n",
            "Epoch 126/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0417 - accuracy: 0.7764 - val_loss: 0.0409 - val_accuracy: 0.7852\n",
            "Epoch 127/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0414 - accuracy: 0.7780 - val_loss: 0.0406 - val_accuracy: 0.7869\n",
            "Epoch 128/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0411 - accuracy: 0.7799 - val_loss: 0.0403 - val_accuracy: 0.7883\n",
            "Epoch 129/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0409 - accuracy: 0.7815 - val_loss: 0.0401 - val_accuracy: 0.7903\n",
            "Epoch 130/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0406 - accuracy: 0.7837 - val_loss: 0.0398 - val_accuracy: 0.7923\n",
            "Epoch 131/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0404 - accuracy: 0.7854 - val_loss: 0.0395 - val_accuracy: 0.7937\n",
            "Epoch 132/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0401 - accuracy: 0.7874 - val_loss: 0.0393 - val_accuracy: 0.7954\n",
            "Epoch 133/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0399 - accuracy: 0.7895 - val_loss: 0.0390 - val_accuracy: 0.7976\n",
            "Epoch 134/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0396 - accuracy: 0.7917 - val_loss: 0.0388 - val_accuracy: 0.7997\n",
            "Epoch 135/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0394 - accuracy: 0.7933 - val_loss: 0.0385 - val_accuracy: 0.8005\n",
            "Epoch 136/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0391 - accuracy: 0.7955 - val_loss: 0.0383 - val_accuracy: 0.8025\n",
            "Epoch 137/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0389 - accuracy: 0.7971 - val_loss: 0.0381 - val_accuracy: 0.8041\n",
            "Epoch 138/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0387 - accuracy: 0.7991 - val_loss: 0.0378 - val_accuracy: 0.8069\n",
            "Epoch 139/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0384 - accuracy: 0.8008 - val_loss: 0.0376 - val_accuracy: 0.8083\n",
            "Epoch 140/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0382 - accuracy: 0.8030 - val_loss: 0.0374 - val_accuracy: 0.8106\n",
            "Epoch 141/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0380 - accuracy: 0.8049 - val_loss: 0.0371 - val_accuracy: 0.8126\n",
            "Epoch 142/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0377 - accuracy: 0.8064 - val_loss: 0.0369 - val_accuracy: 0.8149\n",
            "Epoch 143/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0375 - accuracy: 0.8083 - val_loss: 0.0367 - val_accuracy: 0.8168\n",
            "Epoch 144/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0373 - accuracy: 0.8102 - val_loss: 0.0365 - val_accuracy: 0.8185\n",
            "Epoch 145/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0371 - accuracy: 0.8116 - val_loss: 0.0362 - val_accuracy: 0.8202\n",
            "Epoch 146/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0369 - accuracy: 0.8134 - val_loss: 0.0360 - val_accuracy: 0.8216\n",
            "Epoch 147/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0367 - accuracy: 0.8151 - val_loss: 0.0358 - val_accuracy: 0.8236\n",
            "Epoch 148/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0364 - accuracy: 0.8165 - val_loss: 0.0356 - val_accuracy: 0.8261\n",
            "Epoch 149/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0362 - accuracy: 0.8182 - val_loss: 0.0354 - val_accuracy: 0.8287\n",
            "Epoch 150/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0360 - accuracy: 0.8196 - val_loss: 0.0352 - val_accuracy: 0.8293\n",
            "Epoch 151/200\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0358 - accuracy: 0.8208 - val_loss: 0.0350 - val_accuracy: 0.8303\n",
            "Epoch 152/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0356 - accuracy: 0.8225 - val_loss: 0.0348 - val_accuracy: 0.8313\n",
            "Epoch 153/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0354 - accuracy: 0.8237 - val_loss: 0.0346 - val_accuracy: 0.8326\n",
            "Epoch 154/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0352 - accuracy: 0.8250 - val_loss: 0.0344 - val_accuracy: 0.8339\n",
            "Epoch 155/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0350 - accuracy: 0.8265 - val_loss: 0.0342 - val_accuracy: 0.8354\n",
            "Epoch 156/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0348 - accuracy: 0.8279 - val_loss: 0.0340 - val_accuracy: 0.8361\n",
            "Epoch 157/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0347 - accuracy: 0.8290 - val_loss: 0.0338 - val_accuracy: 0.8378\n",
            "Epoch 158/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0345 - accuracy: 0.8304 - val_loss: 0.0336 - val_accuracy: 0.8388\n",
            "Epoch 159/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0343 - accuracy: 0.8314 - val_loss: 0.0334 - val_accuracy: 0.8396\n",
            "Epoch 160/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0341 - accuracy: 0.8328 - val_loss: 0.0332 - val_accuracy: 0.8404\n",
            "Epoch 161/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0339 - accuracy: 0.8337 - val_loss: 0.0330 - val_accuracy: 0.8414\n",
            "Epoch 162/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0337 - accuracy: 0.8345 - val_loss: 0.0329 - val_accuracy: 0.8425\n",
            "Epoch 163/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0336 - accuracy: 0.8356 - val_loss: 0.0327 - val_accuracy: 0.8435\n",
            "Epoch 164/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0334 - accuracy: 0.8361 - val_loss: 0.0325 - val_accuracy: 0.8445\n",
            "Epoch 165/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0332 - accuracy: 0.8372 - val_loss: 0.0323 - val_accuracy: 0.8450\n",
            "Epoch 166/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0330 - accuracy: 0.8379 - val_loss: 0.0322 - val_accuracy: 0.8457\n",
            "Epoch 167/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0329 - accuracy: 0.8390 - val_loss: 0.0320 - val_accuracy: 0.8462\n",
            "Epoch 168/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0327 - accuracy: 0.8398 - val_loss: 0.0318 - val_accuracy: 0.8472\n",
            "Epoch 169/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0325 - accuracy: 0.8406 - val_loss: 0.0317 - val_accuracy: 0.8482\n",
            "Epoch 170/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0324 - accuracy: 0.8414 - val_loss: 0.0315 - val_accuracy: 0.8483\n",
            "Epoch 171/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0322 - accuracy: 0.8423 - val_loss: 0.0313 - val_accuracy: 0.8490\n",
            "Epoch 172/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0321 - accuracy: 0.8431 - val_loss: 0.0312 - val_accuracy: 0.8502\n",
            "Epoch 173/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0319 - accuracy: 0.8443 - val_loss: 0.0310 - val_accuracy: 0.8511\n",
            "Epoch 174/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0317 - accuracy: 0.8448 - val_loss: 0.0309 - val_accuracy: 0.8515\n",
            "Epoch 175/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0316 - accuracy: 0.8454 - val_loss: 0.0307 - val_accuracy: 0.8521\n",
            "Epoch 176/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0314 - accuracy: 0.8461 - val_loss: 0.0305 - val_accuracy: 0.8526\n",
            "Epoch 177/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0313 - accuracy: 0.8465 - val_loss: 0.0304 - val_accuracy: 0.8536\n",
            "Epoch 178/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0311 - accuracy: 0.8473 - val_loss: 0.0302 - val_accuracy: 0.8544\n",
            "Epoch 179/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0310 - accuracy: 0.8479 - val_loss: 0.0301 - val_accuracy: 0.8548\n",
            "Epoch 180/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0309 - accuracy: 0.8488 - val_loss: 0.0300 - val_accuracy: 0.8557\n",
            "Epoch 181/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0307 - accuracy: 0.8493 - val_loss: 0.0298 - val_accuracy: 0.8557\n",
            "Epoch 182/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0306 - accuracy: 0.8500 - val_loss: 0.0297 - val_accuracy: 0.8564\n",
            "Epoch 183/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0304 - accuracy: 0.8502 - val_loss: 0.0295 - val_accuracy: 0.8576\n",
            "Epoch 184/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0303 - accuracy: 0.8508 - val_loss: 0.0294 - val_accuracy: 0.8582\n",
            "Epoch 185/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0302 - accuracy: 0.8511 - val_loss: 0.0293 - val_accuracy: 0.8587\n",
            "Epoch 186/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0300 - accuracy: 0.8515 - val_loss: 0.0291 - val_accuracy: 0.8593\n",
            "Epoch 187/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0299 - accuracy: 0.8522 - val_loss: 0.0290 - val_accuracy: 0.8597\n",
            "Epoch 188/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0298 - accuracy: 0.8527 - val_loss: 0.0289 - val_accuracy: 0.8599\n",
            "Epoch 189/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0296 - accuracy: 0.8534 - val_loss: 0.0287 - val_accuracy: 0.8608\n",
            "Epoch 190/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0295 - accuracy: 0.8537 - val_loss: 0.0286 - val_accuracy: 0.8615\n",
            "Epoch 191/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0294 - accuracy: 0.8542 - val_loss: 0.0285 - val_accuracy: 0.8621\n",
            "Epoch 192/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0293 - accuracy: 0.8546 - val_loss: 0.0283 - val_accuracy: 0.8622\n",
            "Epoch 193/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0291 - accuracy: 0.8551 - val_loss: 0.0282 - val_accuracy: 0.8629\n",
            "Epoch 194/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.8557 - val_loss: 0.0281 - val_accuracy: 0.8631\n",
            "Epoch 195/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0289 - accuracy: 0.8562 - val_loss: 0.0280 - val_accuracy: 0.8634\n",
            "Epoch 196/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0288 - accuracy: 0.8566 - val_loss: 0.0279 - val_accuracy: 0.8637\n",
            "Epoch 197/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0287 - accuracy: 0.8570 - val_loss: 0.0277 - val_accuracy: 0.8639\n",
            "Epoch 198/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0285 - accuracy: 0.8576 - val_loss: 0.0276 - val_accuracy: 0.8646\n",
            "Epoch 199/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0284 - accuracy: 0.8579 - val_loss: 0.0275 - val_accuracy: 0.8652\n",
            "Epoch 200/200\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0283 - accuracy: 0.8582 - val_loss: 0.0274 - val_accuracy: 0.8656\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdab777f5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzkmBQrZ91zN"
      },
      "source": [
        "### 신경망 모델 정확도 평가 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucTO8Nx4xHxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "899ddf8d-435f-42e0-e473-43aaa7d9d224"
      },
      "source": [
        "model.evaluate(X_valid, y_valid)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.0274 - accuracy: 0.8656\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.02739546447992325, 0.8655999898910522]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIMv2pP2xHxS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "482190c8-5d54-4c1f-e6e3-13ef52b482c6"
      },
      "source": [
        "n = 10\n",
        "pred = model.predict(X_train[n].reshape(-1, 784))\n",
        "print(pred)\n",
        "print(np.argmax(pred))\n",
        "print(y_train[n])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.00565812 0.02403576 0.01892636 0.83675945 0.00120804 0.05522617\n",
            "  0.00200636 0.00752412 0.03864993 0.01000572]]\n",
            "3\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    }
  ]
}